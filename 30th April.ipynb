{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97729ea3-dff0-404e-96e3-7edcf4e7d423",
   "metadata": {},
   "source": [
    "# 1] Explain the concept of homogeneity and completeness in clustering evaluation. How are they calculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbae539-3ab7-4cbd-9820-3a5dab90c189",
   "metadata": {},
   "source": [
    "## 1) Homogeneity \n",
    "### => Measures how pure the clusters are, i.e. how much they contain data points from a single class\n",
    "### => Ranges from 0 to 1 (higher is better)\n",
    "Calculation:\n",
    "- Let \n",
    "        K = number of clusters\n",
    "        N = total number of samples\n",
    "        Ck = set of classes present in cluster k\n",
    "        nk = number of samples in cluster k\n",
    "- Homogeneity = ∑k (nk / N) * max(Ck)\n",
    "- For each cluster k:\n",
    "\n",
    "    Compute fraction of samples in that cluster (nk / N) \n",
    "        \n",
    "    Find dominant class in cluster k (max Ck)\n",
    "        \n",
    "    Multiply above two \n",
    "- Average the score across all clusters\n",
    "\n",
    "## 2) Completeness\n",
    "### => Measures how well data points from a given class are assigned to the same cluster\n",
    "### => Ranges from 0 to 1 (higher is better)  \n",
    "Calculation:\n",
    "- Let\n",
    "        K = number of clusters \n",
    "        C = set of all classes\n",
    "        N = total number of samples\n",
    "        Ck = set of classes present in cluster k\n",
    "        nk = number of samples in cluster k\n",
    "        nc = number of samples of class c\n",
    "- Completeness = ∑c (nc / N) * max(Ck containing c)\n",
    "- For each class c:\n",
    "\n",
    "    Compute fraction of samples of class c (nc / N)\n",
    "        \n",
    "    Find cluster k that contains most samples of class c (max Ck containing c) \n",
    "        \n",
    "    Multiply above two\n",
    "- Average the score across all classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04aceb3-28d8-4252-941e-90231536e492",
   "metadata": {},
   "source": [
    "# 2] What is the V-measure in clustering evaluation? How is it related to homogeneity and completeness?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cabf2-a100-4893-93e9-95b18b810581",
   "metadata": {},
   "source": [
    "### => The V-measure is a metric that combines both homogeneity and completeness to provide an overall assessment of a clustering algorithm's performance. It's a single value that takes into account how well the clusters match the true classes and how well each class is represented within the clusters.\n",
    "\n",
    "### => Mathematically, the V-measure is calculated as the harmonic mean of homogeneity and completeness, taking into consideration their weighted average. It helps to strike a balance between the two:\n",
    "\n",
    "### V = 2 * (homogeneity * completeness) / (homogeneity + completeness)\n",
    "\n",
    "### => In this formula, both homogeneity and completeness are the same as explained earlier. The V-measure ranges from 0 to 1, where higher values indicate better clustering results. Essentially, the V-measure captures the balance between ensuring clusters are pure (homogeneity) and making sure all class members are in the right cluster (completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4ae61-bfca-4063-8d28-77a0857d84f2",
   "metadata": {},
   "source": [
    "# 3] How is the Silhouette Coefficient used to evaluate the quality of a clustering result? What is the range of its values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88abb49-2ff4-4595-b2e1-a547eee59bcc",
   "metadata": {},
   "source": [
    "### => The Silhouette Coefficient is used to evaluate the quality of clustering results by analyzing how well samples are clustered.\n",
    "\n",
    "## 1) What it measures:\n",
    "\n",
    "### => How close each sample in a cluster is to other points in its own cluster.\n",
    "\n",
    "### => How far away each sample is from points in other clusters.\n",
    "## 2) Range of values:\n",
    "\n",
    "### => Silhouette Coefficient ranges from -1 to +1\n",
    "\n",
    "### => Values near +1 indicate clusters are dense and well-separated.\n",
    "\n",
    "### => Values near 0 indicate overlapping clusters.\n",
    "\n",
    "### => Values near -1 indicate misclassified samples.\n",
    "## 3) Calculation:\n",
    "\n",
    "### => For each sample i:\n",
    "\n",
    "### a(i) = Average distance between i and all other points in its cluster\n",
    "\n",
    "### b(i) = Lowest average distance from i to all points in any other cluster\n",
    "\n",
    "### s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
    "## 4) Silhouette Coefficient = Average s(i) over all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c783d54-589b-40b3-950c-fdd4b5b2907f",
   "metadata": {},
   "source": [
    "# 4] How is the Davies-Bouldin Index used to evaluate the quality of a clustering result? What is the range of its values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acefcdff-0844-4998-b3c8-10259fc98837",
   "metadata": {},
   "source": [
    "### => The Davies-Bouldin Index evaluates clustering quality by analyzing both intra-cluster cohesion and inter-cluster separation.\n",
    "\n",
    "## 1) What it measures:\n",
    "\n",
    "### => The average similarity between each cluster and its most similar neighbor.\n",
    "### => Similarity is the ratio of within-cluster distances to between-cluster distances.\n",
    "## 2) Range of values:\n",
    "\n",
    "### => Davies-Bouldin Index ranges from 0 to infinity.\n",
    "### => Values closer to 0 indicate better clustering.\n",
    "### => Lower values correspond to clusters that are compact within themselves and well-separated from each other.\n",
    "## 3) Calculation:\n",
    "\n",
    "### => For each cluster i:\n",
    "\n",
    "### Di = Worst case scenario of average distance between points in cluster i divided by the distance between centroids of cluster i and its most similar cluster.\n",
    "### Davies-Bouldin Index = Average of Di over all clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a0c76-dc85-4366-80eb-61001d9217ae",
   "metadata": {},
   "source": [
    "# 5] Can a clustering result have a high homogeneity but low completeness? Explain with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880e3fa-d941-4c39-b483-8def937a0596",
   "metadata": {},
   "source": [
    "### => Yes, it is possible for a clustering result to have high homogeneity but low completeness. Here is an example:\n",
    "\n",
    "### => Consider a dataset with 3 classes (A, B and C) and 9 total data points.\n",
    "\n",
    "### => A clustering result could look like:\n",
    "\n",
    "### Cluster 1: 2 points from class A\n",
    "### Cluster 2: 3 points from class B\n",
    "### Cluster 3: 1 point from class C\n",
    "### Cluster 4: 1 point from class C\n",
    "### Cluster 5: 1 point from class A\n",
    "### Cluster 6: 1 point from class B\n",
    "\n",
    "### => In this case:\n",
    "\n",
    "### Homogeneity is high (0.89) because each cluster contains predominantly a single class.\n",
    "\n",
    "### But completeness is low (0.56) because points from the same class (especially C) are split across multiple clusters.\n",
    "\n",
    "### This occurs because homogeneity rewards assigning a single dominant class to each cluster, even if points from a given class are scattered across clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2e76a-5780-4eb9-8153-e46b59fee2a6",
   "metadata": {},
   "source": [
    "# 6] How can the V-measure be used to determine the optimal number of clusters in a clustering algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a12a3b-3eed-40b0-aa14-51b78016c064",
   "metadata": {},
   "source": [
    "## 1) Steps:\n",
    "\n",
    "### => Run clustering algorithm (e.g. k-means) with different values for number of clusters k. Common choices are k = 2 to 10.\n",
    "### => For each k, compute:\n",
    "- Homogeneity\n",
    "- Completeness\n",
    "- V-measure (harmonic mean of above two)\n",
    "### => Plot the V-measure for each k.\n",
    "### => Choose k that maximizes the V-measure.\n",
    "## 2) Intuition:\n",
    "\n",
    "### => As k increases, homogeneity tends to go up because more granular clusters can be formed.\n",
    "### => But completeness may decrease if classes get split across too many clusters.\n",
    "### => V-measure balances the two. An \"elbow\" point often emerges - increasing k beyond this over-splits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc5545-fb86-45d6-b6be-79475583024a",
   "metadata": {},
   "source": [
    "# 7] What are some advantages and disadvantages of using the Silhouette Coefficient to evaluate a clustering result?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba68314-6fdf-44e3-a8d5-08eb238c6efd",
   "metadata": {},
   "source": [
    "## 1)Advantages:\n",
    "\n",
    "### => Simple and intuitive interpretation - values close to 1 indicate good clusters.\n",
    "### => Does not require knowledge of ground truth classes.\n",
    "### => Can be applied to any clustering algorithm.\n",
    "### => Useful for comparing results across different runs of the same algorithm.\n",
    "### => Can be used to analyze individual clusters and samples.\n",
    "## 2)Disadvantages:\n",
    "\n",
    "### => Sensitive to noise and outliers which can impact distance calculations.\n",
    "### => Assumes clusters are dense and well-separated, which may not always be true.\n",
    "### => Difficult to evaluate clustering solutions with different number of clusters.\n",
    "### => Does not directly measure accuracy if ground truth labels are available.\n",
    "### => Can suggest misleadingly high scores for poor clustering in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075caa7a-d27f-470c-8806-c461ea869c00",
   "metadata": {},
   "source": [
    "# 8] What are some limitations of the Davies-Bouldin Index as a clustering evaluation metric? How can they be overcome?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6d555-a80f-4000-9718-b73fb34d2e21",
   "metadata": {},
   "source": [
    "## 1) Limitations:\n",
    "\n",
    "### => Assumes clusters have convex shapes and similar density - may fail for irregular shapes.\n",
    "### => Sensitive to outliers which can distort cluster scatter.\n",
    "### => Scale and dimensionality dependent - values hard to compare across datasets.\n",
    "### => Difficult to interpret absolute DB index values.\n",
    "## 2) Ways to overcome limitations:\n",
    "\n",
    "### => Use alongside other metrics like Silhouette Coefficient to get a more comprehensive evaluation.\n",
    "### => Standardize data before computing DB index to handle scale sensitivity.\n",
    "### => Use density-based outlier removal before computing distances.\n",
    "### => Analyze relative change in DB index rather than absolute values for a given dataset.\n",
    "### => Use ground truth class labels if available to supplement with accuracy metrics.\n",
    "### => Compare DB index values to a random baseline to better contextualize the score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcbd3c-0b62-4192-9249-59bf2e2e502c",
   "metadata": {},
   "source": [
    "# 9] What is the relationship between homogeneity, completeness, and the V-measure? Can they have different values for the same clustering result?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c1147-bc83-4bb5-987c-b1d5698399bf",
   "metadata": {},
   "source": [
    "## 1) There is an important relationship between homogeneity, completeness, and V-measure:\n",
    "\n",
    "### => Homogeneity measures the purity of clusters, that is how much they contain data points from a single class.\n",
    "### => Completeness measures how well different data points from a given class are clustered together.\n",
    "### => V-measure combines both metrics by taking their harmonic mean.\n",
    "## 2) For a given clustering result, homogeneity, completeness, and V-measure can have different values:\n",
    "\n",
    "### => It is possible to have high homogeneity but low completeness by splitting classes across clusters. This leads to purer, fragmented clusters.\n",
    "### => Conversely, a giant cluster containing all data would have high completeness but low homogeneity.\n",
    "### => V-measure balances the two by rewarding both intra-cluster purity and inter-cluster completeness.\n",
    "## 3) In most cases:\n",
    "\n",
    "### => Homogeneity and completeness are positively correlated - both increase with better clusters.\n",
    "### => But they can capture different aspects of cluster quality and have tradeoffs.\n",
    "### => V-measure balances the two metrics in a single score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db103c5-f347-46ac-acae-d9cadcf77476",
   "metadata": {},
   "source": [
    "# 10] How can the Silhouette Coefficient be used to compare the quality of different clustering algorithms on the same dataset? What are some potential issues to watch out for?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01ef4e-96b6-4f63-a67d-43e812568fcf",
   "metadata": {},
   "source": [
    "## 1) The Silhouette Coefficient can be used to compare different clustering algorithms on a dataset by:\n",
    "\n",
    "### => Running different algorithms (k-means, hierarchical, etc) on the same dataset\n",
    "### => For each algorithm, calculate the Silhouette Coefficient on the resulting clusters\n",
    "### => Compare Silhouette Coefficient values across algorithms. Higher values indicate better defined, separated clusters.\n",
    "### => Can also calculate Silhouette Coefficient for each cluster to compare granular performance.\n",
    "## 2) Potential issues to watch out for:\n",
    "\n",
    "### => Algorithms may produce different number of clusters, making comparison difficult.\n",
    "### => Silhouette Coefficient assumes clusters are dense and separated - may poorly evaluate algorithms that produce overlapping clusters.\n",
    "### => Results can be sensitive to parameter tuning of each algorithm (e.g k in k-means). Need to optimize each fairly.\n",
    "### => Differences in Silhouette Coefficient across algorithms can be small and not statistically significant.\n",
    "### => Final evaluation should include other metrics like adjusted Rand index compared to ground truth labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dbc26f-ce09-4643-8efa-acdf23275e3d",
   "metadata": {},
   "source": [
    "# 11] How does the Davies-Bouldin Index measure the separation and compactness of clusters? What are some assumptions it makes about the data and the clusters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f3419-5f2a-4126-89d6-3a0760a9ec28",
   "metadata": {},
   "source": [
    "### => For each cluster i, compute Di - the worst-case scenario ratio of within-cluster scatter to between cluster separation for cluster i.\n",
    "### => Within-cluster scatter is measured by average distance between each point and the cluster centroid.\n",
    "### => Between-cluster separation is measured by distance between cluster centroids.\n",
    "### => Di is highest when clusters are compact within themselves but close together.\n",
    "### => Davies-Bouldin Index averages the Di values across all clusters.\n",
    "## Some key assumptions:\n",
    "\n",
    "### => Clusters are convex and relatively similar in size/density.\n",
    "### => Within-cluster scatter is computed using squared Euclidean distance.\n",
    "### => Between-cluster separation uses Euclidean distance between centroids.\n",
    "### => Works best for globs/elliptical shaped clusters that are well separated.\n",
    "### => Performs poorly if clusters are elongated, irregular shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680af641-a64a-423c-b988-a75d2c960495",
   "metadata": {},
   "source": [
    "# 12] Can the Silhouette Coefficient be used to evaluate hierarchical clustering algorithms? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985700a-900f-453e-b5f6-721be5455a99",
   "metadata": {},
   "source": [
    "### Yes, the Silhouette Coefficient can be used to evaluate hierarchical clustering algorithms. Here is how:\n",
    "\n",
    "### => Hierarchical clustering produces a dendrogram showing the nested grouping of data points.\n",
    "\n",
    "### => The dendrogram needs to be cut at some threshold to produce discrete clusters.\n",
    "\n",
    "### => Common approaches for cutting the dendrogram are:\n",
    "\n",
    "- Cutting at a fixed depth/level.\n",
    "- Cutting where the distance between merges is largest.\n",
    "### => Once clusters are obtained by cutting the dendrogram, calculate the Silhouette Coefficient:\n",
    "\n",
    "- Measure intra-cluster cohesion a(i)\n",
    "- Measure inter-cluster separation b(i)\n",
    "- Compute silhouette score s(i) = (b(i)-a(i)) / max(a(i), b(i))\n",
    "### => Average s(i) to get overall Silhouette Coefficient\n",
    "### => Can experiment with different cutoff thresholds and compare Silhouette scores.\n",
    "\n",
    "### => Silhouette Coefficient will assess the compactness and separation of the resulting flat clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0d380-2896-43b0-a165-6be68b7ab9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
