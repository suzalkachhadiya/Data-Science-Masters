{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28147818-c5b4-4c8a-8a01-e73ed65480f7",
   "metadata": {},
   "source": [
    "# 1] What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20817a-07b6-42d1-a41a-1365f0e719e6",
   "metadata": {},
   "source": [
    "### Relationship between Polynomial Functions and Kernel Functions:\n",
    "### => The polynomial kernel function is a specific type of kernel function that computes the similarity between data points using a polynomial function. The polynomial kernel implicitly maps the data into a higher-dimensional feature space, where the decision boundary can be nonlinear. It allows SVMs to capture polynomial relationships between the data points without explicitly computing the polynomial features.\n",
    "\n",
    "### => In other words, while polynomial functions are a specific type of mathematical function used to introduce non-linearity in the feature space, the polynomial kernel is a specific type of kernel function used in SVMs to implicitly capture polynomial relationships between the data points without explicitly expanding the feature space. Polynomial kernels leverage the advantages of polynomial functions by enabling SVMs to model nonlinear decision boundaries based on the polynomial similarity between data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef426b-00e1-48db-a2a9-8a97c225e5b1",
   "metadata": {},
   "source": [
    "# 2] How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3156be5-1ee9-4290-a021-aae5f44be75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_redundant=2,n_repeated=1, random_state=100)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "classifier = SVC(kernel='poly', degree=3, random_state=100)\n",
    "# Here, 'poly' specifies the polynomial kernel, and 'degree' sets the degree of the polynomial\n",
    "\n",
    "# Train the SVM classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec231efa-6866-4629-ae90-aae1029cebaf",
   "metadata": {},
   "source": [
    "# 3] How does increasing the value of epsilon affect the number of support vectors in SVR?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129a870-7245-499f-b6d2-805c05f9c522",
   "metadata": {},
   "source": [
    "### Here's how the increase in epsilon affects the number of support vectors in SVR:\n",
    "\n",
    "## 1) Larger Epsilon:\n",
    "### => When you set a larger value of epsilon, the epsilon-insensitive tube becomes wider. This wider tube allows more data points to fall within the acceptable error range, leading to a larger margin. As a result, more data points can become support vectors as they are closer to or within the margin boundaries.\n",
    "\n",
    "## 2) More Flexibility: \n",
    "### => Increasing epsilon provides more flexibility to the SVR model, allowing it to capture a wider range of data points within the tube. This increased flexibility often leads to a larger number of support vectors as the model adjusts to include more points in the regression estimation.\n",
    "###  \n",
    "### => It's important to note that the number of support vectors can vary depending on the specific dataset and the complexity of the underlying relationship. In general, a larger epsilon tends to increase the number of support vectors, but the exact impact may also depend on other factors such as the complexity of the data distribution, regularization parameters, and the chosen kernel function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1a952-8a52-4dbe-925f-876b643dae51",
   "metadata": {},
   "source": [
    "# 4] How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095991e5-c22f-4e1d-b026-2f0aa72fe9e1",
   "metadata": {},
   "source": [
    "## 1) Kernel Function:\n",
    "### => Different kernel functions capture different types of relationships in the data. For example, a linear kernel assumes a linear relationship, while polynomial and radial basis function (RBF) kernels capture non-linear relationships.\n",
    "### => The choice of the kernel function should align with the underlying data distribution and the complexity of the relationship between the features and the target variable.\n",
    "### => Selecting an appropriate kernel function is essential to ensure the model can accurately represent the patterns and dynamics in the data.\n",
    "### Examples: Linear, Polynomial, RBF (Radial Basis Function), Sigmoid, etc.\n",
    "### Increase: When the data exhibits complex, non-linear relationships, you may want to choose a kernel function that can capture those non-linear patterns. In such cases, increasing the complexity of the kernel function, such as using a Polynomial or RBF kernel, can be beneficial.\n",
    "### Decrease: If the data exhibits a relatively simple, linear relationship, using a linear kernel function may be sufficient. In this case, increasing the complexity of the kernel function may lead to overfitting or unnecessary computational overhead.\n",
    "\n",
    "## 2) C Parameter:\n",
    "### => The C parameter in SVR controls the trade-off between model complexity and error optimization.\n",
    "### => A smaller C value allows more errors (violations of the epsilon-insensitive tube) but results in a larger margin and potentially a simpler model. This can be useful in the presence of outliers or noisy data.\n",
    "### => A larger C value enforces stricter error optimization, leading to a narrower margin and potentially more complex models. This can be beneficial when the data is well-behaved and the goal is to minimize errors.\n",
    "### Examples: Small values (e.g., 0.01, 0.1) for a more flexible model, large values (e.g., 10, 100) for a more focused model.\n",
    "### Increase: When the data is well-behaved and there is no noise or outliers, increasing the C parameter can lead to stricter error optimization. This results in a narrower margin and potentially more complex models that fit the data closely.\n",
    "### Decrease: In the presence of outliers or noisy data, reducing the C parameter allows more errors (violations of the epsilon-insensitive tube) and results in a larger margin. This can help to create a more robust and generalizable model by avoiding overfitting.\n",
    "\n",
    "## 3) Epsilon Parameter:\n",
    "### => The epsilon parameter determines the width of the epsilon-insensitive tube around the regression line.\n",
    "### => A larger epsilon allows more points to fall within the acceptable error range and can result in wider tube boundaries. This can make the model more flexible and capture a wider range of data points.\n",
    "### => Smaller epsilon values result in narrower tube boundaries and stricter error tolerance. This can lead to a more focused model but may be less flexible in capturing diverse patterns.\n",
    "### Examples: Larger values (e.g., 0.1, 0.5) for more flexibility, smaller values (e.g., 0.01, 0.05) for stricter error tolerance.\n",
    "### Increase: When you want the SVR model to be more flexible and capture a wider range of data points, increasing the epsilon parameter widens the epsilon-insensitive tube boundaries. This allows more data points to fall within the acceptable error range, resulting in a more flexible model.\n",
    "### Decrease: If you want the model to be more focused and have stricter error tolerance, reducing the epsilon parameter narrows the tube boundaries. This can lead to a more focused model that pays closer attention to data points within a smaller margin.\n",
    "\n",
    "## 4) Gamma Parameter:\n",
    "### => The gamma parameter is specific to kernel functions like RBF and determines the influence of each training example.\n",
    "### => A larger gamma value makes each training example have a more localized influence, resulting in a more complex decision boundary. This can lead to overfitting if not carefully tuned.\n",
    "### => Smaller gamma values make each training example have a broader influence, resulting in smoother decision boundaries and more generalization.\n",
    "### Examples: Larger values (e.g., 0.1, 1.0) for more localized influence, smaller values (e.g., 0.01, 0.001) for broader influence.\n",
    "### Increase: A higher gamma value gives more localized influence to each training example, resulting in a more complex decision boundary. This can be useful when the data has intricate patterns or sharp transitions between classes.\n",
    "### Decrease: If you want a smoother decision boundary with broader influence from each training example, reducing the gamma parameter can achieve that. Smaller gamma values can help prevent overfitting and promote better generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38932824-9d45-4c9e-967c-191e784858df",
   "metadata": {},
   "source": [
    "# 5] Assignment:\n",
    "## Import the necessary libraries and load the dataset\n",
    "## Split the dataset into training and testing sets\n",
    "## Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "## Create an instance of the SVC classifier and train it on the training data\n",
    "## use the trained classifier to predict the labels of the testing data\n",
    "## Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score)\n",
    "## Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performance\n",
    "## Train the tuned classifier on the entire dataset\n",
    "## Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1c34bc-fd7a-4dd1-bf68-22f131e3a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7124ce39-c14b-49b8-82f0-1b7a3631892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a24881c7-53bb-4976-a98d-f69e3e4aed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4f526e0-4d19-404c-8f97-c53add3c3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.data\n",
    "y=df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "381b17a2-9dca-4aa0-8f5f-806d34788dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.19,random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ddc2310-e6f9-4368-8849-c6a6f7714bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8a75e60-05ce-4f52-9e8f-2f14a6c409d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1ecc7f7-3b83-490a-bc00-7c979150e009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5409dacd-444e-4a31-afd6-97f1a9173575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd306b55-9b8a-4eb3-b186-7e21bf2dc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1a0a439-36dc-4a2f-83c5-d5245306ecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 35  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 37  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 37  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 26  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 28  0  0]\n",
      " [ 0  0  0  0  1  0  0  0 24  1]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d473c3b0-a19b-4624-ae67-7f4df906980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        41\n",
      "           1       1.00      0.98      0.99        42\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.97      1.00      0.99        37\n",
      "           4       0.97      0.97      0.97        33\n",
      "           5       1.00      0.97      0.99        38\n",
      "           6       1.00      1.00      1.00        26\n",
      "           7       1.00      1.00      1.00        28\n",
      "           8       0.96      0.92      0.94        26\n",
      "           9       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.99       342\n",
      "   macro avg       0.99      0.98      0.98       342\n",
      "weighted avg       0.99      0.99      0.99       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ad05708-3a03-4943-ba5f-958e1f65da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter={\n",
    "    \"C\":[0.001,0.01,0.1,1,10],\n",
    "    \"kernel\":[\"poly\",\"rbf\",\"sigmoid\",\"linear\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a67332d-2cec-41d0-9594-104e8dd57841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "classifier=SVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "478427bf-9e60-4eb7-898e-04e6cc0583d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.21,random_state=29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cf741a0-7801-4b89-8f2a-a1e2e36d9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GridSearchCV(classifier,param_grid=parameter,cv=5,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac7c8661-5ba2-4fe1-ad15-ea6b55594b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'kernel': ['poly', 'rbf', 'sigmoid', 'linear']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c559221b-334c-4bf6-92e8-4685f0633bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73c355fb-34a8-4946-a058-0c45c70e89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aade9798-a8c2-4243-bee7-5fb39d380821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b33e2131-5fe7-4c14-b84e-e5b004fa21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svc_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0817b210-fafc-43d3-957e-faceab80c674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
