{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b03d0e",
   "metadata": {},
   "source": [
    "# 1] What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4dd1e",
   "metadata": {},
   "source": [
    "### => Missing values in a dataset refer to the absence of data in one or more cells of the dataset. This can happen due to various reasons, such as data entry errors, technical problems, or incomplete data collection.\n",
    "### \n",
    "### => Handling missing values is essential because they can affect the quality and reliability of the data analysis results. Ignoring missing values can lead to biased or inaccurate conclusions and can also affect the statistical significance of the analysis. Therefore, it is crucial to handle missing values before performing any analysis on the dataset.\n",
    "### \n",
    "### => Some algorithms that are not affected by missing values include tree-based algorithms such as Decision Trees, Random Forests, and Gradient Boosted Trees. These algorithms can handle missing values without any data preprocessing. Another algorithm that can handle missing values is K-Nearest Neighbors (KNN), which can impute missing values using the nearest neighbor method. Additionally, Support Vector Machines (SVM) and Naive Bayes are also not affected by missing values as they use only the available data to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add242c4",
   "metadata": {},
   "source": [
    "# 2] List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa04b3d",
   "metadata": {},
   "source": [
    "## 1) mean / median imputation\n",
    "## 2) random sample imputation\n",
    "## 3) capturing nan value with new feature\n",
    "## 4) end distribution imputation\n",
    "## 5) arbitrary value imputation\n",
    "## 6) frequent category imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96114b5",
   "metadata": {},
   "source": [
    "# 3] Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655b3f0",
   "metadata": {},
   "source": [
    "### => Imbalanced data refers to a dataset where the number of instances in one class is significantly higher or lower than the number of instances in the other class(es).\n",
    "### \n",
    "### => If imbalanced data is not handled\n",
    "## 1) Biased Models: \n",
    "### => When the data is imbalanced, machine learning models can be biased towards the majority class, leading to poor performance on the minority class.\n",
    "### 2) Poor Generalization: \n",
    "### => Models trained on imbalanced data may not generalize well to new data that is balanced.\n",
    "### 3) False Positive/Negative Results:\n",
    "### => In medical or financial applications, for example, an imbalanced dataset can lead to a high number of false positives or false negatives, which can be detrimental.\n",
    "### 4) Poor Decision Making: \n",
    "### => If the model is used for decision-making, it can lead to unfair or inappropriate decisions that negatively impact the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ad5c8",
   "metadata": {},
   "source": [
    "\n",
    "# 4] What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54269f0b",
   "metadata": {},
   "source": [
    "### => Upsampling and downsampling are two techniques used in machine learning to address the issue of imbalanced data, where one class has significantly fewer instances than the other class(es).\n",
    "\n",
    "## 1) Upsampling \n",
    "### => involves increasing the number of instances in the minority class by randomly duplicating instances from that class until the number of instances in that class is equal to or close to the number of instances in the majority class. This technique can be useful for imbalanced datasets with a small number of instances.\n",
    "\n",
    "## 2) Downsampling,\n",
    "### => on the other hand, involves reducing the number of instances in the majority class by randomly removing instances from that class until the number of instances in that class is equal to or close to the number of instances in the minority class. This technique can be useful for imbalanced datasets with a large number of instances.\n",
    "### \n",
    "### => Suppose we have a dataset containing information about credit card transactions, where each transaction is labeled as fraudulent or non-fraudulent. The dataset contains 100,000 transactions, out of which only 1,000 (1%) are labeled as fraudulent, and the rest are non-fraudulent.\n",
    "### => If we choose up-sampling, we would create new synthetic instances of the minority class (fraudulent transactions) to increase their number to be equal to the majority class (non-fraudulent transactions). For example, we might randomly duplicate the 1,000 fraudulent transactions multiple times until the dataset contains 50,000 fraudulent transactions, which is the same number as the non-fraudulent transactions. This technique can help in training the machine learning model on a balanced dataset, which can improve the model's accuracy and generalization.\n",
    "\n",
    "### => On the other hand, if we choose down-sampling, we would randomly remove instances from the majority class (non-fraudulent transactions) until their number matches the minority class (fraudulent transactions). For example, we might randomly remove 49,000 non-fraudulent transactions to make the dataset balanced. However, this technique may result in a loss of information, which can negatively impact the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1c1e9",
   "metadata": {},
   "source": [
    "# 5] What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a9198",
   "metadata": {},
   "source": [
    "### => Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points. \n",
    "### \n",
    "### => One popular data augmentation technique is Synthetic Minority Over-sampling Technique (SMOTE). SMOTE is a method for up-sampling the minority class in an imbalanced dataset. SMOTE creates synthetic instances of the minority class by interpolating between existing instances.\n",
    "### => SMOTE randomly selects a minority class instance from the dataset.\n",
    "### =>It then identifies the k-nearest neighbors of that instance from the minority class.\n",
    "### => SMOTE then selects one of these k-nearest neighbors randomly and computes the difference between the feature values of the minority instance and the selected neighbor.\n",
    "### => SMOTE then multiplies this difference by a random number between 0 and 1 and adds the result to the minority instance to create a new synthetic instance.\n",
    "### => This process is repeated until the desired level of minority class up-sampling is achieved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7046e",
   "metadata": {},
   "source": [
    "# 6] What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5283f",
   "metadata": {},
   "source": [
    "### => Outliers are data points in a dataset that are significantly different from other data points. Outliers can occur due to a variety of reasons, such as measurement errors, data entry errors, or extreme events. Outliers can significantly affect the statistical analysis of a dataset, leading to incorrect conclusions.\n",
    "### \n",
    "### => Handling outliers is important because they can distort statistical analyses and lead to incorrect conclusions. Outliers can affect measures such as mean and standard deviation, which are commonly used in statistical analysis, making them less representative of the actual data. In addition, outliers can also impact machine learning algorithms, as they can skew the decision boundaries and negatively affect the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc33b3",
   "metadata": {},
   "source": [
    "# 7] You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceda3f7",
   "metadata": {},
   "source": [
    "### => mean/median imputation\n",
    "### => random sample imputation\n",
    "### => frequent category imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf7c2f",
   "metadata": {},
   "source": [
    "# 8] You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152103a",
   "metadata": {},
   "source": [
    "### => look for the patterns / creating plots\n",
    "### => check for correlation between the missing data and other variables\n",
    "### => use imputations techniques because there is a small percentage of the data is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49941311",
   "metadata": {},
   "source": [
    "# 9] Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f9767",
   "metadata": {},
   "source": [
    "### => we can use SMOTE technique.\n",
    "### => we can do data inter polation\n",
    "### => we can use upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b16b5",
   "metadata": {},
   "source": [
    "# 10] When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d073a816",
   "metadata": {},
   "source": [
    "## 1) Undersampling: \n",
    "### => This involves randomly removing instances from the majority class until the dataset is balanced. This method can be useful when the dataset is large, and removing instances does not result in significant information loss.\n",
    "\n",
    "## 2) Oversampling:\n",
    "### => This involves creating new instances for the minority class to balance the dataset. This can be done by replicating existing instances or generating synthetic instances using techniques like SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "## 3) Stratified Sampling:\n",
    "### => This involves sampling the dataset in a way that ensures that the proportion of each class in the sample is the same as the proportion of each class in the original dataset.\n",
    "\n",
    "## 4) Weighting:\n",
    "### => This involves giving more weight to the minority class during model training. This can be done by using techniques like class weighting or cost-sensitive learning.\n",
    "\n",
    "## 5) Ensemble methods:\n",
    "### => This involves training multiple models on different subsets of the dataset and combining their predictions to make a final prediction. This can help to reduce the impact of the majority class on the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948e81f",
   "metadata": {},
   "source": [
    "# 11] You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61ac78",
   "metadata": {},
   "source": [
    "## 1) Oversampling:\n",
    "### => This involves creating new instances for the minority class to balance the dataset. This can be done by replicating existing instances or generating synthetic instances using techniques like SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "## 2) Synthetic Sampling: \n",
    "### => This involves creating new instances for the minority class using statistical methods such as bootstrapping, which randomly resamples the available data to create a new dataset.\n",
    "\n",
    "## 4) Cost-Sensitive Learning: \n",
    "### => This involves assigning higher costs to errors in predicting the minority class. This can be done by adjusting the cost matrix or by using a different loss function that emphasizes the minority class.\n",
    "\n",
    "## 5) Anomaly Detection: \n",
    "### => This involves identifying the minority class as an anomaly or outlier and using methods such as one-class classification or clustering to identify the minority class.\n",
    "\n",
    "## 6) Ensemble Methods: This involves training multiple models on different subsets of the dataset and combining their predictions to make a final prediction. This can help to reduce the impact of the minority class on the final prediction.\n",
    "### \n",
    "### =>It is important to note that each method has its own advantages and disadvantages, and the choice of method will depend on the specific characteristics of the dataset and the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadb9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
